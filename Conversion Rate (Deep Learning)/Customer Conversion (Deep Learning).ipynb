{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiobooks business case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Importing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data from the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_csv_data = np.loadtxt('C:\\\\Users\\\\akhan\\\\Desktop\\\\datasets\\\\Audiobooks_data.csv', delimiter=',')\n",
    "\n",
    "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
    "targets_all = raw_csv_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.7300e+02, 2.1600e+03, 2.1600e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [6.1100e+02, 1.4040e+03, 2.8080e+03, ..., 0.0000e+00, 1.8200e+02,\n",
       "        1.0000e+00],\n",
       "       [7.0500e+02, 3.2400e+02, 3.2400e+02, ..., 1.0000e+00, 3.3400e+02,\n",
       "        1.0000e+00],\n",
       "       ...,\n",
       "       [2.8671e+04, 1.0800e+03, 1.0800e+03, ..., 0.0000e+00, 2.9000e+01,\n",
       "        0.0000e+00],\n",
       "       [3.1134e+04, 2.1600e+03, 2.1600e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [3.2832e+04, 1.6200e+03, 1.6200e+03, ..., 0.0000e+00, 9.0000e+01,\n",
       "        0.0000e+00]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_one_targets = int(np.sum(targets_all))\n",
    "\n",
    "zero_targets_counter = 0\n",
    "\n",
    "indices_to_remove = []\n",
    "\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] == 0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "\n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis=0)\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "as it is a classification problem, we balance the data to have equal number of each label 50%-50% (0 and 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_deep_learning = StandardScaler()\n",
    "scaled_inputs = scaler_deep_learning.fit_transform(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4474"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_inputs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "split: training: 80%, validation: 10%, test: 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_count = int(0.8 * samples_count)\n",
    "validation_samples_count = int(0.1 * samples_count)\n",
    "\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797.0 3579 0.5020955574182733\n",
      "223.0 447 0.4988814317673378\n",
      "217.0 448 0.484375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the three datasets in *.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Audiobooks_data_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('Audiobooks_data_validation', inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez('Audiobooks_data_test', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler_deep_learning, open('scaler_deep_learning.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Building The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')    \n",
    "                            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "max_epochs=100\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7670 - val_loss: 0.4531 - val_accuracy: 0.8613\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3829 - accuracy: 0.8748 - val_loss: 0.3339 - val_accuracy: 0.8792\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3131 - accuracy: 0.8874 - val_loss: 0.3031 - val_accuracy: 0.8881\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.8908 - val_loss: 0.2865 - val_accuracy: 0.8926\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 944us/step - loss: 0.2792 - accuracy: 0.8919 - val_loss: 0.2800 - val_accuracy: 0.8971\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 997us/step - loss: 0.2714 - accuracy: 0.8935 - val_loss: 0.2703 - val_accuracy: 0.8971\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2627 - accuracy: 0.8983 - val_loss: 0.2748 - val_accuracy: 0.9016\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 0.2584 - accuracy: 0.9019 - val_loss: 0.2742 - val_accuracy: 0.9060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20b256b4460>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_inputs,\n",
    "          train_targets,\n",
    "          batch_size=batch_size,\n",
    "          epochs=max_epochs,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(validation_inputs, validation_targets),\n",
    "          verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577900</td>\n",
       "      <td>0.766974</td>\n",
       "      <td>0.453062</td>\n",
       "      <td>0.861298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.382877</td>\n",
       "      <td>0.874825</td>\n",
       "      <td>0.333909</td>\n",
       "      <td>0.879195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.313053</td>\n",
       "      <td>0.887399</td>\n",
       "      <td>0.303096</td>\n",
       "      <td>0.888143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.291815</td>\n",
       "      <td>0.890752</td>\n",
       "      <td>0.286550</td>\n",
       "      <td>0.892617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.279249</td>\n",
       "      <td>0.891869</td>\n",
       "      <td>0.279998</td>\n",
       "      <td>0.897092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.271440</td>\n",
       "      <td>0.893546</td>\n",
       "      <td>0.270328</td>\n",
       "      <td>0.897092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.262668</td>\n",
       "      <td>0.898296</td>\n",
       "      <td>0.274785</td>\n",
       "      <td>0.901566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.258393</td>\n",
       "      <td>0.901928</td>\n",
       "      <td>0.274178</td>\n",
       "      <td>0.906040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.577900  0.766974  0.453062      0.861298\n",
       "1  0.382877  0.874825  0.333909      0.879195\n",
       "2  0.313053  0.887399  0.303096      0.888143\n",
       "3  0.291815  0.890752  0.286550      0.892617\n",
       "4  0.279249  0.891869  0.279998      0.897092\n",
       "5  0.271440  0.893546  0.270328      0.897092\n",
       "6  0.262668  0.898296  0.274785      0.901566\n",
       "7  0.258393  0.901928  0.274178      0.906040"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loss = pd.DataFrame(model.history.history)\n",
    "df_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Testing The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 784us/step - loss: 0.2242 - accuracy: 0.9219\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.22. Test accuracy: 92.19%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability of each class:\n",
    "first column is probability of being 0 or not buy and second column is probability of being 1 or buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15, 0.85],\n",
       "       [0.86, 0.14],\n",
       "       [1.  , 0.  ],\n",
       "       [0.23, 0.77],\n",
       "       [0.98, 0.02],\n",
       "       [0.95, 0.05],\n",
       "       [0.07, 0.93],\n",
       "       [1.  , 0.  ],\n",
       "       [0.89, 0.11],\n",
       "       [0.18, 0.82],\n",
       "       [0.89, 0.11],\n",
       "       [0.93, 0.07],\n",
       "       [0.93, 0.07],\n",
       "       [0.86, 0.14],\n",
       "       [0.  , 1.  ],\n",
       "       [0.94, 0.06],\n",
       "       [1.  , 0.  ],\n",
       "       [0.96, 0.04],\n",
       "       [0.96, 0.04],\n",
       "       [0.91, 0.09],\n",
       "       [0.85, 0.15],\n",
       "       [0.  , 1.  ],\n",
       "       [0.29, 0.71],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.26, 0.74],\n",
       "       [0.81, 0.19],\n",
       "       [0.22, 0.78],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.92, 0.08],\n",
       "       [0.92, 0.08],\n",
       "       [0.24, 0.76],\n",
       "       [0.  , 1.  ],\n",
       "       [0.93, 0.07],\n",
       "       [0.92, 0.08],\n",
       "       [0.95, 0.05],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.86, 0.14],\n",
       "       [0.  , 1.  ],\n",
       "       [0.35, 0.65],\n",
       "       [0.93, 0.07],\n",
       "       [0.17, 0.83],\n",
       "       [0.13, 0.87],\n",
       "       [0.39, 0.61],\n",
       "       [0.26, 0.74],\n",
       "       [0.54, 0.46],\n",
       "       [0.94, 0.06],\n",
       "       [0.94, 0.06],\n",
       "       [0.89, 0.11],\n",
       "       [1.  , 0.  ],\n",
       "       [0.52, 0.48],\n",
       "       [0.23, 0.77],\n",
       "       [0.25, 0.75],\n",
       "       [0.17, 0.83],\n",
       "       [1.  , 0.  ],\n",
       "       [0.83, 0.17],\n",
       "       [0.92, 0.08],\n",
       "       [0.21, 0.79],\n",
       "       [0.89, 0.11],\n",
       "       [0.18, 0.82],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.33, 0.67],\n",
       "       [0.  , 1.  ],\n",
       "       [0.17, 0.83],\n",
       "       [0.92, 0.08],\n",
       "       [0.27, 0.73],\n",
       "       [0.01, 0.99],\n",
       "       [0.  , 1.  ],\n",
       "       [0.86, 0.14],\n",
       "       [0.97, 0.03],\n",
       "       [1.  , 0.  ],\n",
       "       [0.13, 0.87],\n",
       "       [0.94, 0.06],\n",
       "       [0.78, 0.22],\n",
       "       [0.93, 0.07],\n",
       "       [0.91, 0.09],\n",
       "       [0.15, 0.85],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.26, 0.74],\n",
       "       [0.63, 0.37],\n",
       "       [0.91, 0.09],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.26, 0.74],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.93, 0.07],\n",
       "       [0.  , 1.  ],\n",
       "       [0.95, 0.05],\n",
       "       [0.27, 0.73],\n",
       "       [1.  , 0.  ],\n",
       "       [0.01, 0.99],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.24, 0.76],\n",
       "       [0.  , 1.  ],\n",
       "       [0.26, 0.74],\n",
       "       [1.  , 0.  ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.76, 0.24],\n",
       "       [0.  , 1.  ],\n",
       "       [0.47, 0.53],\n",
       "       [0.84, 0.16],\n",
       "       [0.33, 0.67],\n",
       "       [0.18, 0.82],\n",
       "       [0.15, 0.85],\n",
       "       [0.93, 0.07],\n",
       "       [0.95, 0.05],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.96, 0.04],\n",
       "       [0.85, 0.15],\n",
       "       [0.99, 0.01],\n",
       "       [0.15, 0.85],\n",
       "       [0.42, 0.58],\n",
       "       [0.16, 0.84],\n",
       "       [0.24, 0.76],\n",
       "       [0.41, 0.59],\n",
       "       [0.19, 0.81],\n",
       "       [0.  , 1.  ],\n",
       "       [0.29, 0.71],\n",
       "       [0.93, 0.07],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.88, 0.12],\n",
       "       [0.93, 0.07],\n",
       "       [0.76, 0.24],\n",
       "       [0.33, 0.67],\n",
       "       [0.88, 0.12],\n",
       "       [0.19, 0.81],\n",
       "       [1.  , 0.  ],\n",
       "       [0.23, 0.77],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.87, 0.13],\n",
       "       [0.91, 0.09],\n",
       "       [0.24, 0.76],\n",
       "       [0.84, 0.16],\n",
       "       [0.  , 1.  ],\n",
       "       [0.94, 0.06],\n",
       "       [0.23, 0.77],\n",
       "       [0.87, 0.13],\n",
       "       [0.  , 1.  ],\n",
       "       [0.92, 0.08],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.21, 0.79],\n",
       "       [0.88, 0.12],\n",
       "       [0.85, 0.15],\n",
       "       [0.19, 0.81],\n",
       "       [0.22, 0.78],\n",
       "       [0.93, 0.07],\n",
       "       [0.64, 0.36],\n",
       "       [0.69, 0.31],\n",
       "       [0.26, 0.74],\n",
       "       [0.9 , 0.1 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.25, 0.75],\n",
       "       [0.17, 0.83],\n",
       "       [0.82, 0.18],\n",
       "       [0.92, 0.08],\n",
       "       [0.  , 1.  ],\n",
       "       [0.91, 0.09],\n",
       "       [0.55, 0.45],\n",
       "       [0.93, 0.07],\n",
       "       [0.17, 0.83],\n",
       "       [0.  , 1.  ],\n",
       "       [0.33, 0.67],\n",
       "       [1.  , 0.  ],\n",
       "       [0.94, 0.06],\n",
       "       [0.26, 0.74],\n",
       "       [0.16, 0.84],\n",
       "       [0.92, 0.08],\n",
       "       [0.87, 0.13],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.38, 0.62],\n",
       "       [0.86, 0.14],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.29, 0.71],\n",
       "       [0.  , 1.  ],\n",
       "       [0.92, 0.08],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.22, 0.78],\n",
       "       [1.  , 0.  ],\n",
       "       [0.93, 0.07],\n",
       "       [0.19, 0.81],\n",
       "       [0.28, 0.72],\n",
       "       [0.85, 0.15],\n",
       "       [0.  , 1.  ],\n",
       "       [0.95, 0.05],\n",
       "       [0.71, 0.29],\n",
       "       [0.27, 0.73],\n",
       "       [0.76, 0.24],\n",
       "       [0.93, 0.07],\n",
       "       [0.93, 0.07],\n",
       "       [0.  , 1.  ],\n",
       "       [0.83, 0.17],\n",
       "       [1.  , 0.  ],\n",
       "       [0.96, 0.04],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.17, 0.83],\n",
       "       [0.29, 0.71],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.95, 0.05],\n",
       "       [0.  , 1.  ],\n",
       "       [0.29, 0.71],\n",
       "       [0.01, 0.99],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.92, 0.08],\n",
       "       [0.89, 0.11],\n",
       "       [0.  , 1.  ],\n",
       "       [0.92, 0.08],\n",
       "       [0.94, 0.06],\n",
       "       [0.98, 0.02],\n",
       "       [0.28, 0.72],\n",
       "       [0.96, 0.04],\n",
       "       [0.2 , 0.8 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.29, 0.71],\n",
       "       [0.93, 0.07],\n",
       "       [0.  , 1.  ],\n",
       "       [0.41, 0.59],\n",
       "       [0.01, 0.99],\n",
       "       [1.  , 0.  ],\n",
       "       [0.06, 0.94],\n",
       "       [0.07, 0.93],\n",
       "       [0.  , 1.  ],\n",
       "       [0.03, 0.97],\n",
       "       [0.87, 0.13],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.93, 0.07],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.89, 0.11],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.33, 0.67],\n",
       "       [0.13, 0.87],\n",
       "       [0.82, 0.18],\n",
       "       [0.  , 1.  ],\n",
       "       [0.95, 0.05],\n",
       "       [0.19, 0.81],\n",
       "       [1.  , 0.  ],\n",
       "       [0.95, 0.05],\n",
       "       [0.86, 0.14],\n",
       "       [0.81, 0.19],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.94, 0.06],\n",
       "       [1.  , 0.  ],\n",
       "       [0.27, 0.73],\n",
       "       [0.29, 0.71],\n",
       "       [0.24, 0.76],\n",
       "       [0.89, 0.11],\n",
       "       [0.07, 0.93],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.91, 0.09],\n",
       "       [0.92, 0.08],\n",
       "       [0.29, 0.71],\n",
       "       [1.  , 0.  ],\n",
       "       [0.23, 0.77],\n",
       "       [0.82, 0.18],\n",
       "       [0.88, 0.12],\n",
       "       [0.32, 0.68],\n",
       "       [0.  , 1.  ],\n",
       "       [0.86, 0.14],\n",
       "       [0.32, 0.68],\n",
       "       [0.25, 0.75],\n",
       "       [0.33, 0.67],\n",
       "       [0.94, 0.06],\n",
       "       [0.03, 0.97],\n",
       "       [0.  , 1.  ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.03, 0.97],\n",
       "       [0.15, 0.85],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.42, 0.58],\n",
       "       [0.  , 1.  ],\n",
       "       [0.43, 0.57],\n",
       "       [0.96, 0.04],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.26, 0.74],\n",
       "       [1.  , 0.  ],\n",
       "       [0.22, 0.78],\n",
       "       [0.27, 0.73],\n",
       "       [0.93, 0.07],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.92, 0.08],\n",
       "       [1.  , 0.  ],\n",
       "       [0.29, 0.71],\n",
       "       [0.04, 0.96],\n",
       "       [0.  , 1.  ],\n",
       "       [0.29, 0.71],\n",
       "       [0.24, 0.76],\n",
       "       [1.  , 0.  ],\n",
       "       [0.19, 0.81],\n",
       "       [0.25, 0.75],\n",
       "       [0.88, 0.12],\n",
       "       [1.  , 0.  ],\n",
       "       [0.85, 0.15],\n",
       "       [0.98, 0.02],\n",
       "       [1.  , 0.  ],\n",
       "       [0.42, 0.58],\n",
       "       [0.  , 1.  ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.05, 0.95],\n",
       "       [0.  , 1.  ],\n",
       "       [0.88, 0.12],\n",
       "       [0.38, 0.62],\n",
       "       [0.19, 0.81],\n",
       "       [0.87, 0.13],\n",
       "       [0.08, 0.92],\n",
       "       [0.91, 0.09],\n",
       "       [0.91, 0.09],\n",
       "       [0.19, 0.81],\n",
       "       [0.93, 0.07],\n",
       "       [0.89, 0.11],\n",
       "       [0.93, 0.07],\n",
       "       [0.93, 0.07],\n",
       "       [0.85, 0.15],\n",
       "       [1.  , 0.  ],\n",
       "       [0.93, 0.07],\n",
       "       [0.96, 0.04],\n",
       "       [0.21, 0.79],\n",
       "       [0.99, 0.01],\n",
       "       [0.03, 0.97],\n",
       "       [0.93, 0.07],\n",
       "       [0.16, 0.84],\n",
       "       [0.88, 0.12],\n",
       "       [0.93, 0.07],\n",
       "       [0.85, 0.15],\n",
       "       [1.  , 0.  ],\n",
       "       [0.78, 0.22],\n",
       "       [0.23, 0.77],\n",
       "       [0.95, 0.05],\n",
       "       [0.  , 1.  ],\n",
       "       [0.91, 0.09],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.23, 0.77],\n",
       "       [1.  , 0.  ],\n",
       "       [0.04, 0.96],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.03, 0.97],\n",
       "       [0.77, 0.23],\n",
       "       [0.23, 0.77],\n",
       "       [0.41, 0.59],\n",
       "       [0.29, 0.71],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.15, 0.85],\n",
       "       [0.72, 0.28],\n",
       "       [1.  , 0.  ],\n",
       "       [0.31, 0.69],\n",
       "       [0.  , 1.  ],\n",
       "       [0.23, 0.77],\n",
       "       [0.95, 0.05],\n",
       "       [0.27, 0.73],\n",
       "       [0.88, 0.12],\n",
       "       [0.99, 0.01],\n",
       "       [0.35, 0.65],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.14, 0.86],\n",
       "       [1.  , 0.  ],\n",
       "       [0.78, 0.22],\n",
       "       [0.42, 0.58],\n",
       "       [0.92, 0.08],\n",
       "       [0.93, 0.07],\n",
       "       [0.88, 0.12],\n",
       "       [1.  , 0.  ],\n",
       "       [0.88, 0.12],\n",
       "       [0.89, 0.11],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.94, 0.06],\n",
       "       [0.29, 0.71],\n",
       "       [0.96, 0.04],\n",
       "       [0.26, 0.74],\n",
       "       [0.2 , 0.8 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.84, 0.16],\n",
       "       [1.  , 0.  ],\n",
       "       [0.19, 0.81],\n",
       "       [1.  , 0.  ],\n",
       "       [0.94, 0.06],\n",
       "       [0.77, 0.23],\n",
       "       [0.27, 0.73],\n",
       "       [0.91, 0.09],\n",
       "       [0.31, 0.69],\n",
       "       [0.23, 0.77],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.89, 0.11],\n",
       "       [0.86, 0.14],\n",
       "       [0.93, 0.07],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.22, 0.78],\n",
       "       [0.98, 0.02],\n",
       "       [0.  , 1.  ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.45, 0.55],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.2 , 0.8 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.93, 0.07],\n",
       "       [0.06, 0.94],\n",
       "       [0.19, 0.81],\n",
       "       [0.  , 1.  ],\n",
       "       [0.19, 0.81],\n",
       "       [0.18, 0.82],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.93, 0.07],\n",
       "       [0.85, 0.15],\n",
       "       [0.  , 1.  ],\n",
       "       [0.98, 0.02],\n",
       "       [0.13, 0.87],\n",
       "       [1.  , 0.  ],\n",
       "       [0.03, 0.97],\n",
       "       [0.31, 0.69],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.92, 0.08],\n",
       "       [0.16, 0.84],\n",
       "       [0.93, 0.07],\n",
       "       [0.08, 0.92],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.99, 0.01],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.92, 0.08],\n",
       "       [0.26, 0.74],\n",
       "       [0.92, 0.08]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_pr = model.predict(test_inputs).round(2)\n",
    "predictions_pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can get prediction label of each observation using these methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(test_inputs), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict_classes(test_inputs)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[207  24]\n",
      " [ 19 198]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix :')\n",
    "print(confusion_matrix(test_targets, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       223\n",
      "           1       0.92      0.93      0.92       225\n",
      "\n",
      "    accuracy                           0.92       448\n",
      "   macro avg       0.92      0.92      0.92       448\n",
      "weighted avg       0.92      0.92      0.92       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification report :')\n",
    "print(classification_report(test_targets, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2_new_PY",
   "language": "python",
   "name": "tf2_new_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
